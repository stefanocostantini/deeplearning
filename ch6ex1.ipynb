{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Intro: one-hot encoding of text using Keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot word encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word-level\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "# Create a tokenizer that takes the first 1,000 common words into account\n",
    "tokenizer = Tokenizer(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sat': 3, 'mat': 5, 'my': 8, 'dog': 6, 'homework': 9, 'the': 1, 'ate': 7, 'on': 4, 'cat': 2}\n"
     ]
    }
   ],
   "source": [
    "# Now fit the tokenizer on the data\n",
    "tokenizer.fit_on_texts(samples)\n",
    "# This builds the word index, which can be also saved as a variable as follows\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "# Now we can used the tokenizer to create a sequence of integers\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# And we can also use the tokenizer to do the one-hot encoding directly.\n",
    "one_hot = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot word encoding with hashing trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we hash words into a vector of fixed size\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "dimensionality = 1000\n",
    "max_length = 10\n",
    "results = np.zeros((len(samples), max_length, dimensionality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each word is hashed into a random integer index between 0 and 1,000\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word)) % dimensionality\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are low-dimensional floating-point vectors which are learnt from data. Typical dimensions when dealing with large vocabularies is 256, 512 or 1,024.\n",
    "\n",
    "There are two ways to obtain embeddings: \n",
    "- Learn word embeddings jointly with the main task you care about\n",
    "- Use pre-trained word embeddings, we will explore both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning word embeddings\n",
    "The geometric relationships between word vectors should reflect the semantic relationships between these words. \n",
    "In other words we want to map human language into a geometric space.\n",
    "Because the mapping can be different depending on the context, it makes sense to learn the embedding for each specific task. This is done by learning the weights of an Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding layer can be also seen as a dictionary that maps integer indices (which stand for specific words) to dense vectors.\n",
    "The Embedding layer takes as input a 2D tensor of integers, of shape `(samples, sequence_length)`, where each entry is a sequence of integers.\n",
    "The Embedding layer returns a 3D floating-point tensor of shape `(samples, sequence_ length, embedding_dimensionality)`. Such a 3D tensor can then be processed by an RNN layer or a 1D convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now learn an embedding layer in the context of doing a sentiment analysis of IMDB reviews\n",
    "# First we load and prepare the data\n",
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "# Set the maximum number of features (the dimensionality of the embedding layer)\n",
    "max_features = 10000\n",
    "# Now set the maximum number of words to consider (the lenght of the sequence)\n",
    "maxlen = 20\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data( num_words=max_features)\n",
    "# Then turn the lists of integers into a 2D integer tensor of shape (samples, maxlen)\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now let's set up and train the network using the embedding layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# We specify the maximum input length to the Embedding layer so we can later flatten the embedded inputs.\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "# We then flatten the 3D tensor of embeddings into a 2D tensor of shape (samples, maxlen * 8)\n",
    "model.add(Flatten())\n",
    "# And finally a binary classifier\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.6701 - acc: 0.6223 - val_loss: 0.6242 - val_acc: 0.7072\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 0.5491 - acc: 0.7500 - val_loss: 0.5294 - val_acc: 0.7412\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 0.4634 - acc: 0.7876 - val_loss: 0.5021 - val_acc: 0.7548\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 0.4185 - acc: 0.8138 - val_loss: 0.4968 - val_acc: 0.7576\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 0.3876 - acc: 0.8307 - val_loss: 0.5001 - val_acc: 0.7586\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 0.3620 - acc: 0.8427 - val_loss: 0.5051 - val_acc: 0.7572\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 0.3392 - acc: 0.8558 - val_loss: 0.5114 - val_acc: 0.7548\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 0.3185 - acc: 0.8682 - val_loss: 0.5188 - val_acc: 0.7530\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 0.2988 - acc: 0.8781 - val_loss: 0.5271 - val_acc: 0.7532\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 0.2809 - acc: 0.8868 - val_loss: 0.5368 - val_acc: 0.7504\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is ~75%, which is good because it's a simple network which only takes into account the first 20 words of each review. Moreover, such a model doesn't take the order and the relationship of words into account. For that we would need to use a 1D convnet or an RNN. We'll explore these later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a pre-trained embedding can be done when we don't have enough data to learn our own embedding. There are various precomputed databases of word embeddings that can be downloaded and used in a Keras Embedding layer. Word2Vec is one of them. Another popular one is GloVe.\n",
    "The example below uses GloVe (but the same approach can be used for Word2Vec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first load the raw imdb data and process the labels\n",
    "import os\n",
    "\n",
    "imdb_dir = '/home/ec2-user/datasets/imdb/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can tokenize the data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "# We cut reviews at 100 words\n",
    "maxlen = 100\n",
    "# We train on 200 samples...\n",
    "training_samples = 200\n",
    "# ...and validate on 10000 samples\n",
    "validation_samples = 10000\n",
    "# We consider only the top 10000 words in the Tokenizing datasets\n",
    "max_words = 10000\n",
    "# Set up the tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to make the sequences all of the same length, padding when necessary\n",
    "data = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (25000, 100)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now split the data into training and test set. We shuffle the data first because the data is ordered\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Now let's load up the GloVe embeddings\n",
    "glove_dir = '/home/ec2-user/datasets/word_embeddings/'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll build an embedding matrix that we can load into an Embedding layer. It must be a matrix of shape `(max_words, embedding_dim)`, where each entry i contains the `embedding_dim`-dimensional vector for the word of index i in the reference word index (built during tokenization). Note that index 0 isn’t supposed to stand for any word or token—it’s a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the GloVe word-embeddings matrix\n",
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now let's define the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 320,065\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# And now we can load the embeddings matrix into the embedding layer.\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "# We also freeze the weights\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.2841 - acc: 0.5000 - val_loss: 0.7208 - val_acc: 0.5231\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.5755 - acc: 0.6450 - val_loss: 0.9998 - val_acc: 0.5026\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3532 - acc: 0.8850 - val_loss: 0.8355 - val_acc: 0.5179\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3546 - acc: 0.8350 - val_loss: 0.6916 - val_acc: 0.5744\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.1921 - acc: 0.9700 - val_loss: 1.1691 - val_acc: 0.4997\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.2005 - acc: 0.9350 - val_loss: 0.7264 - val_acc: 0.5742\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0842 - acc: 0.9950 - val_loss: 0.8951 - val_acc: 0.5202\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.1406 - acc: 0.9650 - val_loss: 0.9763 - val_acc: 0.5143\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0545 - acc: 1.0000 - val_loss: 0.7653 - val_acc: 0.5698\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.7677 - val_acc: 0.5855\n"
     ]
    }
   ],
   "source": [
    "# Let's now train, evaluate and save the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model.save_weights('/home/ec2-user/models/imdb/pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7iIiMaRwFxGJIYW7iEgMKdxFRGLo/wO7Fsaduh7I3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00a7667780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00a5dc62b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model starts to overfit pretty quickly, which is to be expected given that there are so few training sample.\n",
    "\n",
    "We can also re-run the model without loading the pre-trained embeddings. This is generally more powerful as the embeddings will be specific to the problem at hand, but in the case we only have 200 training samples, so the performance won't be very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6937 - acc: 0.5450 - val_loss: 0.6920 - val_acc: 0.5197\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.5052 - acc: 0.9700 - val_loss: 0.6953 - val_acc: 0.5170\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.2778 - acc: 0.9900 - val_loss: 0.6951 - val_acc: 0.5272\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.1245 - acc: 1.0000 - val_loss: 0.6972 - val_acc: 0.5304\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0595 - acc: 1.0000 - val_loss: 0.7016 - val_acc: 0.5265\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.7026 - val_acc: 0.5321\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.7070 - val_acc: 0.5312\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7108 - val_acc: 0.5347\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.7130 - val_acc: 0.5348\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.7226 - val_acc: 0.5389\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the performance of trained embedding is basically the same as that of the learned embedding. If we were to increase the training sample, this would increase. Let's try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_samples = 1000\n",
    "x_train_more = data[:new_training_samples]\n",
    "y_train_more = labels[:new_training_samples]\n",
    "x_val_more = data[new_training_samples: new_training_samples + validation_samples]\n",
    "y_val_more = labels[new_training_samples: new_training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6911 - acc: 0.5320 - val_loss: 0.6909 - val_acc: 0.5072\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4523 - acc: 0.9500 - val_loss: 0.6681 - val_acc: 0.5933\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1342 - acc: 0.9950 - val_loss: 0.6937 - val_acc: 0.5927\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6868 - val_acc: 0.6211\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.7124 - val_acc: 0.6267\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 7.4301e-04 - acc: 1.0000 - val_loss: 0.7782 - val_acc: 0.6298\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.3273e-04 - acc: 1.0000 - val_loss: 0.8969 - val_acc: 0.6222\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3177e-05 - acc: 1.0000 - val_loss: 0.8488 - val_acc: 0.6383\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 4.2758e-06 - acc: 1.0000 - val_loss: 0.8948 - val_acc: 0.6427\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 8.0082e-07 - acc: 1.0000 - val_loss: 0.9645 - val_acc: 0.6435\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train_more, y_train_more,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val_more, y_val_more))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the validation accuracy increases to ~64%, thanks to using more training samples.\n",
    "Finally, let’s evaluate the model on the test data. First, we need to tokenize the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_dir = '/home/ec2-user/datasets/imdb/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 94us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.76388788042068478, 0.58016000000000001]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('/home/ec2-user/models/imdb/pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a pretty low accuracy of ~58%, due to the fact that the saved model only had a handful of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
