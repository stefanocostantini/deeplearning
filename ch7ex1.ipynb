{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We show how a sequential model can be written in functional form\n",
    "# First the \"classic\" way\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# And now its functional equivalent\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# We now define the model, just by specifying the input and the output tensors\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "# And finally we can see its structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to consider three ways in which the functionality API can be helpful:\n",
    "* Multi-input models\n",
    "* Multi-output models\n",
    "* Graph-like models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-input models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider a simple example, a question-answering model. This will take two inputs:\n",
    "# - The question\n",
    "# - Some reference text with information on how to answer\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# The input is a variable-length sequence of integers\n",
    "# After definining it, we embed it into a sequence vector of size 64\n",
    "# Then encode it in a single vector via a LSTM\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# Now let's follow the same process for the question input\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# We then concatenate the text and the question\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "# And finally we add a softmax classifier on top, as output layer\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "# Let's now instantiate the model, specifying the two inputs and the output\n",
    "model = Model([text_input, question_input], answer)\n",
    "\n",
    "# And finally we compile it\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we train this model? There are two possible APIs:\n",
    "1. Feed the model a list of Numpy arrays as inputs\n",
    "2. Feed it a dictionary that maps input names to Numpy arrays (this option is only available if we give names ot the inputs) \n",
    "\n",
    "We show both below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0000e+00 - acc: 0.6190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac6c31bcc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# Defining some dummy input and output data\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "# We can fit the model by feeding a list of Numpy arrays (not run)\n",
    "# model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# Or we can fit it using a dictionary of inputs (only if inputs are named)\n",
    "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example is a network that attempts to simultaneously predict different properties of the data, such as a network that takes as input a series of social media posts from a single anonymous person and tries to predict attributes of that person, such as age, gender, and income level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_group = 10\n",
    "\n",
    "# A single input type, which we first embed in a vector the size of \n",
    "# the vocabulary and then we process with Conv1D layers\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# And now we can set up the different output layers, each with a given name\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_group, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "# Finally we instantiate the model, specifying the single input and the various outputs\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training such a model requires the ability to specify different loss functions for different heads of the network: for instance, age prediction is a scalar regression task, but gender prediction is a binary classification task, requiring a different training procedure.\n",
    "But because gradient descent requires you to minimize a scalar, you must combine these losses into a single value in order to train the model. The simplest way to combine different losses is to sum them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compile the model to allow for multiple outputs, given different weights to the various losses\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse', \n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "             loss_weights={'age': 0.25,\n",
    "                           'income': 1.,\n",
    "                           'gender': 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally we would fit the model by specifying a dictionary of arrays (but for the outputs this time)\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "                   epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed acyclic graphs of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the functional API, not only can you build models with multiple inputs and mul- tiple outputs, but you can also implement networks with a complex internal topology. Neural networks in Keras are allowed to be arbitrary directed acyclic graphs of layers.\n",
    "Several common neural-network components are implemented as graphs. Two notable ones are Inception modules and residual connections. We consider them in turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inception modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a popular type of network architecture for convolutional neural networks. It consists of a stack of modules that themselves look like small independent networks, split into several parallel branches. Assuming the existence of a 4D input tensor `x`, this is how the network on page 243 can be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the full Inception V3 architecture is available in Keras as `keras.applications .inception_v3.InceptionV3`, including weights pretrained on the ImageNet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual connections are a common graph-like network component found in many post- 2015 network architectures, including Xception. They tackle two common problems that plague any large-scale deep-learning model: vanishing gradients and representational bottlenecks. In general, adding residual connections to any model that has more than 10 layers is likely to be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A residual connection consists of making the output of an earlier layer available as input to a later layer, effectively creating a shortcut in a sequential network. Rather than being concatenated to the later activation, the earlier output is summed with the later activation, which assumes that both activations are the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of residual connection in Keras when the feature-map sizes are the same\n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "# Here we add the original x back to the output features\n",
    "y = layers.add([y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of residual connection when the feature-map sizes are different\n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# We use a 1x1 convolution to linearly downsample the original x tensor to the same shape as y\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "\n",
    "# Here we add the transformed x back to the output features\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer weight sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more important feature of the functional API is the ability to reuse a layer instance several times. When you call a layer instance twice, instead of instantiating a new layer for each call, you reuse the same weights with every call. This allows you to build models that have shared branches—several branches that all share the same knowledge and perform the same operations. That is, they share the same representations and learn these representations simultaneously for different sets of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how to implement a model with two inputs that can be interchanged\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# We instantiate a LSTM layer only once\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "# Now we build the left side of the network\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "# And then the right one\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# Then we concatenate the layers\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "\n",
    "# And build the classifier on top\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# Finally we instantiate and train the model. When this model is trained\n",
    "# the weights of the LSTM layer are updated based on both layers\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, in the functional API, models can be used as you’d use layers—effectively, you can think of a model as a “bigger layer.” This is true of both the Sequential and Model classes. This means you can call a model on an input tensor and retrieve an output tensor.\n",
    "When you call a model instance, you’re reusing the weights of the model—exactly like what happens when you call a layer instance. Calling an instance, whether it’s a layer instance or a model instance, will always reuse the existing learned representations of the instance—which is intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple practical example of what you can build by reusing a model instance is a vision model that uses a dual camera as its input: two parallel cameras, a few centi- meters (one inch) apart. Such a model can perceive depth, which can be useful in many applications. You shouldn’t need two independent models to extract visual features from the left camera and the right camera before merging the two feeds. Here’s how you’d implement a Siamese vision model (shared convolutional base) in Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "# The base image-processing model is the Xception network (convolutional base only)\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "# The inputs are 250 × 250 RGB images.\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "# We call the same vision model twice\n",
    "left_features = xception_base(left_input)\n",
    "right_input = xception_base(right_input)\n",
    "\n",
    "# The merged features contain information from the right visual feed and the left visual feed.\n",
    "merged_features = layers.concatenate([left_features, right_input], axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
